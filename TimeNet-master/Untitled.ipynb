{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 18129819954233674812\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4251716424907609144\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5060693856\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4568953413862815985\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13180721813535250776\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import itertools\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from timenet import TimeNet, SimpleSeriesGenerator, normalize_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_rate=None\n",
    "early_stop=10\n",
    "learning_rate=.005\n",
    "embeddings_dim = 64\n",
    "n_epochs = 10\n",
    "batch_size = 2\n",
    "num_layers = 1\n",
    "dropout=.4\n",
    "normalize = \"none\"#['none', 'zscore', 'minmax']\n",
    "model_name = 'enc'\n",
    "dynamic_batches=True\n",
    "training_file = \"D:\\Work\\TimeNet-master\\data\\dataset_train.feather\"\n",
    "validation_file =\"D:\\Work\\TimeNet-master\\data\\dataset_valid.feather\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  dataset                             series_id     value  \\\n",
      "0        ItalyPowerDemand  67995397-e0d9-4399-b2b7-aa955552af7c -0.710518   \n",
      "1        ItalyPowerDemand  67995397-e0d9-4399-b2b7-aa955552af7c -1.183320   \n",
      "2        ItalyPowerDemand  67995397-e0d9-4399-b2b7-aa955552af7c -1.372442   \n",
      "3        ItalyPowerDemand  67995397-e0d9-4399-b2b7-aa955552af7c -1.593083   \n",
      "4        ItalyPowerDemand  67995397-e0d9-4399-b2b7-aa955552af7c -1.467002   \n",
      "...                   ...                                   ...       ...   \n",
      "2326353         ShapesAll  178b6700-e471-46fc-adf1-50e9e4bddfd4  1.311526   \n",
      "2326354         ShapesAll  178b6700-e471-46fc-adf1-50e9e4bddfd4  1.332473   \n",
      "2326355         ShapesAll  178b6700-e471-46fc-adf1-50e9e4bddfd4  1.355873   \n",
      "2326356         ShapesAll  178b6700-e471-46fc-adf1-50e9e4bddfd4  1.377027   \n",
      "2326357         ShapesAll  178b6700-e471-46fc-adf1-50e9e4bddfd4  1.398365   \n",
      "\n",
      "        class  \n",
      "0           1  \n",
      "1           1  \n",
      "2           1  \n",
      "3           1  \n",
      "4           1  \n",
      "...       ...  \n",
      "2326353    58  \n",
      "2326354    58  \n",
      "2326355    58  \n",
      "2326356    58  \n",
      "2326357    58  \n",
      "\n",
      "[2326358 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "dst_train = pd.read_feather(training_file)\n",
    "print(dst_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_series_data(filename):\n",
    "    dst_train = pd.read_feather(filename)\n",
    "    series = dst_train[['series_id', 'value']].groupby(by='series_id')['value'].apply(np.array)\n",
    "    series = pd.DataFrame({'series': series, 'length': series.apply(len)}).sort_values(by='length', ascending=False).reset_index()\n",
    "    return series[['series_id', 'series']], series['length'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  series_id  \\\n",
      "0      4c3b4de4-c315-402b-94d6-21d582fc9f94   \n",
      "1      c022f81d-7927-4374-81ec-581c64613955   \n",
      "2      c0142947-2352-4ef0-ac2f-0b1bfe2f3d28   \n",
      "3      6b9a24fa-e1b5-44f7-a91e-f0d198215308   \n",
      "4      d1069661-1bd1-493f-8839-8a1825b5e905   \n",
      "...                                     ...   \n",
      "10935  5728da4e-f6e0-4697-a99c-ab0adc6d16af   \n",
      "10936  1d40e6d3-618b-4453-9df1-0cb32fab50cc   \n",
      "10937  b7ac3bd3-a2fd-4ec4-bbc3-d2d77a0c51be   \n",
      "10938  1d513b1b-4cd6-446d-8535-f2719cef1c12   \n",
      "10939  ea0128e1-9362-4139-8b4d-eb2c0b31006d   \n",
      "\n",
      "                                                  series  \n",
      "0      [1.9665286, 1.8997803, 1.8332209, 1.7668505, 1...  \n",
      "1      [0.5258499, 0.54246599, 0.50590382, 0.48555841...  \n",
      "2      [1.7834022, 1.7849346, 1.7869075, 1.789314, 1....  \n",
      "3      [1.6507212, 1.5952497, 1.5399348, 1.4847766, 1...  \n",
      "4      [1.4747435, 1.4603898, 1.4472921, 1.435464, 1....  \n",
      "...                                                  ...  \n",
      "10935  [0.038482736, -0.5156686, -0.93128209, -1.2083...  \n",
      "10936  [-0.77677379, -1.3357222, -1.4672394, -1.56587...  \n",
      "10937  [0.31992897, -0.69037301, -1.195524, -0.791403...  \n",
      "10938  [-0.74769628, -1.2071241, -1.34225, -1.3692752...  \n",
      "10939  [-0.94329127, -1.1153575, -1.5332324, -1.70529...  \n",
      "\n",
      "[10940 rows x 2 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'print(train_data.shape)\\nprint(type(train_data))'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_train, maxlen = read_series_data(training_file)\n",
    "print(series_train)\n",
    "print(type(series_train))\n",
    "print(maxlen)\n",
    "series_valid, _ = read_series_data(validation_file)\n",
    "train_data = series_train['series']\n",
    "valid_data = series_valid['series']\n",
    "\"\"\"print(train_data.shape)\n",
    "print(type(train_data))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_valid_sets(series, validation_split=0.2, batch_size=32):\n",
    "    x = range(series.shape[0])\n",
    "    batches = int(np.floor(series.shape[0] / batch_size))\n",
    "    batches_train, batches_valid = train_test_split(range(batches), test_size=validation_split, random_state=0)\n",
    "    idx_train = sorted(itertools.chain(*[x[(ind * batch_size):((ind + 1) * batch_size)] for ind in batches_train]))\n",
    "    idx_valid = sorted(itertools.chain(*[x[(ind * batch_size):((ind + 1) * batch_size)] for ind in batches_valid]))\n",
    "    return series.iloc[idx_train], series.iloc[idx_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(train_data, enc, log_dir, normalize=True):\n",
    "    print(\"Creating reconstructions...\")\n",
    "    pd.concat([pd.DataFrame({'index': k,\n",
    "                             'series': normalize_series(train_data.tolist()[k], normalize),\n",
    "                             'decoded': enc.decode(train_data.iloc[k])})\n",
    "               for k in range(len(train_data))], axis='rows')\\\n",
    "        .reset_index()\\\n",
    "        .to_feather(os.path.join(log_dir, 'reconstructed_train.feather'))\n",
    "\n",
    "def read_series_metadata(filename):\n",
    "    dst_train = pd.read_feather(filename)\n",
    "    return dst_train[['dataset','series_id', 'class']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         [(None, None, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 1)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "encode_1 (GRU)                  [(None, None, 64), ( 12864       masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "drop_encode_1 (Dropout)         (None, None, 64)     0           encode_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ReverseV2 (TensorFl [(None, None, 64)]   0           drop_encode_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "drop_decode_1 (Dropout)         (None, None, 64)     0           tf_op_layer_ReverseV2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decode_1 (GRU)                  (None, None, 64)     24960       drop_decode_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_dist (TimeDistributed)     (None, None, 1)      65          decode_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None, 1)      0           time_dist[0][0]                  \n",
      "                                                                 main_input[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 37,889\n",
      "Trainable params: 37,889\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Loading models\\64_x1_drop40_enc\\weights.h5...\n",
      "Epoch 1/10\n",
      "   1/5470 [..............................] - ETA: 0s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_error: 0.1852WARNING:tensorflow:From D:\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/5470 [..............................] - ETA: 20:07 - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_error: 0.1771WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0329s vs `on_train_batch_end` time: 0.4080s). Check your callbacks.\n",
      " 436/5470 [=>............................] - ETA: 1:28 - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_error: 0.1967"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Work\\TimeNet-master\\timenet.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  X = np.array([x for x in X if x is not None])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5470/5470 [==============================] - 104s 19ms/step - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_error: 0.1982 - val_loss: nan - val_root_mean_squared_error: nan - val_mean_absolute_error: nan - val_mean_squared_logarithmic_error: 0.2062ithm - ETA: 1:13 - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_error: - ETA: 1:13 - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_error - ETA: 1:12 - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_erro - ETA: 1:12 - loss: nan - root_\n",
      "Epoch 2/10\n",
      "5470/5470 [==============================] - 103s 19ms/step - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_error: 0.1982 - val_loss: nan - val_root_mean_squared_error: nan - val_mean_absolute_error: nan - val_mean_squared_logarithmic_error: 0.2062\n",
      "Epoch 3/10\n",
      "5470/5470 [==============================] - 101s 19ms/step - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_error: 0.1982 - val_loss: nan - val_root_mean_squared_error: nan - val_mean_absolute_error: nan - val_mean_squared_logarithmic_error: 0.20623s - loss: nan - root_mean_squared_error: nan - mean - ETA: 8s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - me - ETA: 6s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan -  - ETA: 4s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - me - ETA: 2s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_error: 0.198 - ETA: 2s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan \n",
      "Epoch 4/10\n",
      "5470/5470 [==============================] - 103s 19ms/step - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_error: 0.1982 - val_loss: nan - val_root_mean_squared_error: nan - val_mean_absolute_error: nan - val_mean_squared_logarithmic_error: 0.2062 - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_erro - ETA: 1:11 - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarith - ETA: 1:11 - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - - ETA: 1:09 - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmi -  - ETA: 1:00 - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squa - ETA: 59s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean - ETA: 58s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_e - ETA: 57s - loss: na - ETA: 35s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logar - ETA: 35s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logar - ETA: 34s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_error: 0. - ETA: 34s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - me - ETA: 33s - loss: nan - root_mean_squa - ETA: 30s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: na - ETA: 29s - loss: nan - root_mean_squared_error: nan - mean_ab - ETA: 27s - loss: nan - root_mean_squared_error: nan - m - ETA: 25s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_error: 0.19 - ETA: 25s - loss: nan - root_mean_squared_error: n - ETA - ETA: 19s - loss:  - ETA: 7s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_error: 0 - E\n",
      "Epoch 5/10\n",
      "5470/5470 [==============================] - 102s 19ms/step - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_error: 0.1982 - val_loss: nan - val_root_mean_squared_error: nan - val_mean_absolute_error: nan - val_mean_squared_logarithmic_error: 0.2062red_error: nan - - ETA: 47s - loss: nan - root_mean_squared_error: nan - ETA: 35s - loss: nan - root_mean_squared_error: nan - mean_abso - ETA: 33 - ETA: 14s - loss: nan - root_mean_squared_error: nan - mean_absolute_err - ETA: 13s - loss: nan - root_mean_squared_error: nan - mean_absolu - ETA: 11s - loss: nan - root_mean_squared_error: nan - ETA: 9s - loss: - ETA: 3s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared - ETA: 1s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_s\n",
      "Epoch 6/10\n",
      "5470/5470 [==============================] - 102s 19ms/step - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_error: 0.1982 - val_loss: nan - val_root_mean_squared_error: nan - val_mean_absolute_error: nan - val_mean_squared_logarithmic_error: 0.2062squared_logarithmic_error: 0. - ETA: 39s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squ - - ETA: 34s - loss: nan - root_mean_squared_error: nan - mean_absolute_error - ETA: 33\n",
      "Epoch 7/10\n",
      "5470/5470 [==============================] - 103s 19ms/step - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_error: 0.1982 - val_loss: nan - val_root_mean_squared_error: nan - val_mean_absolute_error: nan - val_mean_squared_logarithmic_error: 0.2062- root_mean_squared_error: nan - mean_absolute_error: nan - mean_\n",
      "Epoch 8/10\n",
      "5470/5470 [==============================] - 101s 18ms/step - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_error: 0.1982 - val_loss: nan - val_root_mean_squared_error: nan - val_mean_absolute_error: nan - val_mean_squared_logarithmic_error: 0.2062: 8s - loss: nan -  - ETA: 2s - loss: nan - root_mean_squared_error: nan - mean_absolute_error\n",
      "Epoch 9/10\n",
      "5470/5470 [==============================] - 103s 19ms/step - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_error: 0.1982 - val_loss: nan - val_root_mean_squared_error: nan - val_mean_absolute_error: nan - val_mean_squared_logarithmic_error: 0.2062oss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_erro - ETA: 1:03 - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_e - ETA: 1:02 - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan  - ETA: 40s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_error: 0. - ETA: 40s  - ETA: 11s - loss: nan - roo - ETA: 8s - l - ETA: 1s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared - ETA: 0s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_error\n",
      "Epoch 10/10\n",
      "5470/5470 [==============================] - 104s 19ms/step - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_error: 0.1982 - val_loss: nan - val_root_mean_squared_error: nan - val_mean_absolute_error: nan - val_mean_squared_logarithmic_error: 0.2062solute_error: nan - mean_squared_logarithmic - ETA: 1:11 - loss: nan - root_mean_squared_error:  - ETA: 1:08 - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logari - ETA: 1:06 - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_log - ETA: 1:05 - loss: n - ETA: 59s - loss: nan - root_mean_squared_error: nan - mean_absolute_error:  - ETA: 58s - loss: nan - root_mean_sq - ETA: 23s - loss: nan - root_mean_ - ETA: 20s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squ - ETA: 19s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_e - ETA: 19s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logarithmic_error: 0. - ETA: 18s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squ - ETA: 18s - loss: nan - root_mean_ - ETA: 15s - loss: nan - root_mean_squared_error: nan - mean_absolute_e - ETA: 13s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logar - ETA: 13s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean - ETA: 12s - loss: nan - root_mean_squared_error: nan - mean_absolute - ETA: 10s - loss: na - ETA: 5s - loss: nan - root_mean_squared_error: nan - mean_absolute_error: nan - mean_squared_logari - ETA: 4s - loss: nan - root_mean_squared_error: na\n",
      "{'loss': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'root_mean_squared_error': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'mean_absolute_error': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'mean_squared_logarithmic_error': [0.19818589091300964, 0.19818589091300964, 0.19818611443042755, 0.19818592071533203, 0.19818627834320068, 0.19818618893623352, 0.19818612933158875, 0.19818612933158875, 0.19818618893623352, 0.19818580150604248], 'val_loss': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_root_mean_squared_error': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_mean_absolute_error': [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], 'val_mean_squared_logarithmic_error': [0.20617619156837463, 0.20617619156837463, 0.20617619156837463, 0.20617619156837463, 0.20617619156837463, 0.20617619156837463, 0.20617619156837463, 0.20617619156837463, 0.20617619156837463, 0.20617619156837463], 'lr': [0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005]}\n",
      "Creating embeddings for the series dataset...\n",
      "5470/5470 [==============================] - 21s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "\"\"\"if training_file is None or len(training_file.strip()) == 0 or not os.path.isfile(training_file):\n",
    "    raise Exception(f\"Training dataset {training_file} does not exist\")\n",
    "\n",
    "if validation_file is None or len(validation_file.strip()) == 0 or not os.path.isfile(validation_file):\n",
    "    warnings.warn(f\"Validation dataset {training_file} does not exist, will use training dataset for validation\")\n",
    "    validation_file = None\n",
    "\n",
    "if validation_file is None:\n",
    "    series_train, maxlen = read_series_data(training_file)\n",
    "    train_data, valid_data = create_train_valid_sets(series_train['series'], batch_size=batch_size)\n",
    "else:\"\"\"\n",
    "if dynamic_batches is True:\n",
    "    maxlen = None\n",
    "train_generator = SimpleSeriesGenerator(train_data, batch_size=batch_size, X_only=False, normalize=normalize, maxlen=maxlen)\n",
    "valid_generator = SimpleSeriesGenerator(valid_data, batch_size=batch_size, X_only=False, normalize=normalize, maxlen=maxlen)\n",
    "enc = TimeNet(embeddings_dim, num_layers=num_layers, batch_size=batch_size, model_name=model_name, dropout=dropout)\n",
    "history, log_dir = enc.train(train_generator, nb_epoch=n_epochs, validation_data=valid_generator,\n",
    "                             finetune_rate=finetune_rate, lr=learning_rate, early_stop=early_stop)\n",
    "print(history.history)\n",
    "print(\"Creating embeddings for the series dataset...\")\n",
    "generator = SimpleSeriesGenerator(train_data, batch_size=batch_size, X_only=True, normalize=normalize, maxlen=maxlen)\n",
    "embed_train = enc.encode(generator)\n",
    "embed_train = pd.DataFrame(embed_train)\n",
    "embed_train.columns = list(map(str, range(embed_train.shape[1])))\n",
    "embed_train['series_id'] = series_train['series_id']\n",
    "train_meta = read_series_metadata(training_file)\n",
    "embed_train = embed_train.merge(train_meta, on='series_id')\n",
    "embed_train.to_feather(os.path.join(log_dir, 'embeddings.feather'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
